{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg)\n",
    "\n",
    "<center>\n",
    "<h1><font size=\"+3\">GSFC Python Bootcamp</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<CENTER>\n",
    "<H1 style=\"color:red\">\n",
    "An Introduction to h5py\n",
    "</H1>\n",
    "</CENTER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Useful References </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <A HREF=\"https://buildmedia.readthedocs.org/media/pdf/h5py/latest/h5py.pdf\">h5py Documentation</A>\n",
    "* <A HREF=\"https://www.christopherlovell.co.uk/blog/2016/04/27/h5py-intro.html\">h5py: reading and writing HDF5 files in Python</A>\n",
    "* <A HREF=\"https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/\">How to use HDF5 files in Python</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> What we will cover </font>\n",
    "* Opening a file\n",
    "* Dimension\n",
    "* Variables\n",
    "* Attributes\n",
    "* Writing data\n",
    "* Creating groups\n",
    "* Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> What is h5py?</font>\n",
    "\n",
    "* An HDF5 file is a container for two kinds of objects: \n",
    "   1. **Datasets**:, Array-like collections of data.\n",
    "   2. **Groups**: Folder-like containers that hold datasets and other groups.\n",
    "* h5py is the Python interface to the HDF5.\n",
    "* Relies on NumPy arrays.\n",
    "* Within h5py, HDF5 groups work like dictionaries, and datasets work like NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import six\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Opening a netCDF File</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdFileName = 'sample_hdf5.h5'\n",
    "modeType   = 'w'\n",
    "hdfid = h5py.File(hdFileName, modeType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `modeType`: 'w', 'r+', 'r', or 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdfid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Data Compression </font>\n",
    "* When saving data, you may opt for compressing it using different algorithms. \n",
    "* h5py supports a few compression filters such as GZIP, LZF, and SZIP. \n",
    "* When using one of the compression filters, the data will be processed on its way to the disk and it will be decompressed when reading it. \n",
    "* When readding data, the underlying HDF5 library automatically extracts the data from the compressed datasets with the appropriate algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzip compression flag\n",
    "comp = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specify the data type to optimize space\n",
    "* Set data compression if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Creating Dimensions in a HDF5 File</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latitude    \n",
    "lat = np.arange(-90,91,2.0)\n",
    "dset = hdfid.require_dataset('lat', \n",
    "                            shape=lat.shape, \n",
    "                            dtype=np.float32, \n",
    "                            compression=\"gzip\", compression_opts=comp)\n",
    "dset[...] = lat\n",
    "dset.attrs['name'] = 'latitude'\n",
    "dset.attrs['units'] = 'degrees north'\n",
    "\n",
    "# Longitude\n",
    "lon = np.arange(-180,180,2.5)\n",
    "dset = hdfid.require_dataset('lon', \n",
    "                            shape=lon.shape, \n",
    "                            dtype=np.float32, \n",
    "                            compression=\"gzip\", compression_opts=comp)\n",
    "dset[...] = lon\n",
    "dset.attrs['name'] = 'longitude'\n",
    "dset.attrs['units'] = 'degrees east'\n",
    "\n",
    "# Vertical levels\n",
    "lev = np.arange(0,72,1)\n",
    "dset = hdfid.require_dataset('lev', \n",
    "                            shape=lev.shape, \n",
    "                            dtype=np.int, \n",
    "                            compression=\"gzip\", compression_opts=comp)\n",
    "dset[...] = lev\n",
    "dset.attrs.update({'name': 'vertical levels',\n",
    "                   'units': 'hPa'})\n",
    "\n",
    "# Time (note the unlimited dimension)\n",
    "time = np.arange(0,1,1)\n",
    "dset = hdfid.require_dataset('time', \n",
    "                             shape=time.shape, \n",
    "                             maxshape=(None), \n",
    "                             dtype=np.float32, compression=comp)\n",
    "dset[...] = time\n",
    "dset.attrs['name'] = 'time'\n",
    "dset.attrs['units'] = 'hours since 2013-01-01 00:00:00.0'\n",
    "dset.attrs['calendar'] = 'gregorian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Create Variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrecs = 5\n",
    "arr = np.zeros((nrecs,lev.size,lat.size,lon.size))\n",
    "arr[0:nrecs,:,:,:] = 300*np.random.uniform(\n",
    "                                size=(nrecs,lev.size,lat.size,lon.size))\n",
    "dset = hdfid.require_dataset('temp', shape=arr.shape, \n",
    "                                 dtype=np.float32, compression=comp)\n",
    "dset[...] = arr\n",
    "dset.attrs['name'] = 'temperature'\n",
    "dset.attrs['units'] = 'K'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `create_dataset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.zeros((lat.size,lon.size))\n",
    "arr2[:,:] = np.random.random(size=(lat.size,lon.size))\n",
    "landfrac = hdfid.create_dataset('landfrac', data=arr2, dtype=np.float32)\n",
    "landfrac.attrs['name'] = 'Fraction of land'\n",
    "landfrac.attrs['units'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Adding Global Attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfid.attrs['Description'] = 'Sample HDF5 file'\n",
    "hdfid.attrs['History']     = 'Created for the h5py Tutorial'\n",
    "hdfid.attrs['Source']      = 'NASA GSFC'\n",
    "hdfid.attrs['HDF5_Version'] = six.u(h5py.version.hdf5_version)\n",
    "hdfid.attrs['h5py_version'] = six.u(h5py.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_attr = {'Date': dt.datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\"), \n",
    "            'User': 'ASTG',}\n",
    "hdfid.attrs.update(glob_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the formulation based on `json` to write metadata in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "metadata = {'Note': 'Another way to add metadata in file', \n",
    "            'OS': os.name,}\n",
    "m = hdfid.create_dataset('metadata', data=json.dumps(metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Printing File Attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in hdfid.attrs.keys():\n",
    "    print('{} => {}'.format(k, hdfid.attrs[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_read = json.loads(hdfid['metadata'][()])\n",
    "for k in metadata_read:\n",
    "    print('{} => {}'.format(k, metadata_read[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>List all Variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in hdfid:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Create Groups</font>\n",
    "* We can organize data in hierarchical groups, which are analogous to directories in a filesystem. \n",
    "* Groups serve as containers for variables, dimensions and attributes, as well as other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpData2D = hdfid.create_group('2D_Data')\n",
    "gpData2D.attrs['Description'] = \"Group for 2D variables\"\n",
    "gpData2D.attrs['Sub groups'] = \"Land and Sea\"\n",
    "\n",
    "sgpLand  = gpData2D.create_group('2D_Land')\n",
    "sgpSea   = gpData2D.create_group('2D_Sea')\n",
    "\n",
    "gpData3D = hdfid.create_group('3D_Data')\n",
    "gpData3D.attrs['Description'] = \"Group for 2D variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all variables and top groups\n",
    "for item in hdfid:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parent of \"2D_Land\" is {}'.format(sgpLand.parent))\n",
    "print('Parent of \"3D_Data\" is {}'.format(gpData3D.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in gpData2D.attrs.keys():\n",
    "    print('{} => {}'.format(j, gpData2D.attrs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in gpData2D:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all top variables and top groups in a file\n",
    "for key in hdfid.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visit()` method allows to list all the nested groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(name):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfid.visit(get_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visititems()` method allows you to view all items in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "def get_all_objs(name, obj):\n",
    "    attr = list(obj.attrs.items())\n",
    "    print(name, obj, attr)\n",
    "    x = obj.attrs.get('x',None)\n",
    "    if x: \n",
    "        results.append((name, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfid.visititems(get_all_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add variable to a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.zeros((nrecs,lat.size,lon.size))\n",
    "arr2[0:nrecs,:,:] = 300*np.random.uniform(\n",
    "                                size=(nrecs,lat.size,lon.size))\n",
    "surf_pres = sgpLand.create_dataset('sp', data=arr2)\n",
    "surf_pres.attrs['name'] = 'Surface Pressure'\n",
    "surf_pres.attrs['units'] = 'Pa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = gpData3D.create_dataset('temp', data=arr)\n",
    "temp.attrs['name'] = 'temperature (3D)'\n",
    "temp.attrs['units'] = 'K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdfid[\"3D_Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdfid[\"2D_Data/2D_Land\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in hdfid.attrs.keys():\n",
    "    print('{} => {}'.format(j, hdfid.attrs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in gpData2D.attrs.keys():\n",
    "    print('{} => {}'.format(j, gpData2D.attrs[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Close the file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Reading a HDF5 File</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('sample_hdf5.h5', 'r') as hdfid:\n",
    "     print(hdfid.keys())\n",
    "\n",
    "     lev  = hdfid['lev'].value\n",
    "     lat  = hdfid['lat'].value\n",
    "     lon  = hdfid['lon'].value\n",
    "     time = hdfid['time'].value\n",
    "\n",
    "     temp1 = hdfid['temp'].value\n",
    "     print(temp1[0,0,0,0], temp1[4,6,7,15])\n",
    "\n",
    "     temp2 = hdfid['3D_Data']['temp'].value\n",
    "     print(temp2[0,0,0,0], temp2[4,6,7,15])     \n",
    "        \n",
    "     surf_pres = hdfid['2D_Data/2D_Land']['sp'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp1.shape)\n",
    "print(np.min(temp1), np.max(temp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp2.shape)\n",
    "print(np.min(temp2), np.max(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surf_pres.shape)\n",
    "print(np.min(surf_pres), np.max(surf_pres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Updating a Variable in an Existing HDF5 File</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdFileName, mode='a') as hdfid:\n",
    "     temp = hdfid['temp'].value\n",
    "     data = temp[:]\n",
    "     data = 1.1*data + 100.0\n",
    "     temp[:] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)\n",
    "print(np.min(temp), np.max(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Resizing Datasets</font>\n",
    "* Datasets can be resized once created up to a maximum size. \n",
    "* You specify this maximum size when creating the dataset, via the keyword `maxshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('resize_dataset.h5', 'w') as hdfid:\n",
    "    d = hdfid.create_dataset('dataset', (100, ),  maxshape=(500, ))\n",
    "    d[:100] = np.random.randn(100)\n",
    "    d.resize((200,))\n",
    "    d[100:200] = np.random.randn(100)\n",
    "\n",
    "with h5py.File('resize_dataset.h5', 'r') as hdfid:\n",
    "    dset = hdfid['dataset']\n",
    "    print(dset[99])\n",
    "    print(dset[199])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also resize the dataset at a later stage, don't need to do it in the same session when you created the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('resize_dataset.h5', 'a') as hdfid:\n",
    "    dset = hdfid['dataset']\n",
    "    dset.resize((300,))\n",
    "    dset[:200] = 0\n",
    "    dset[200:300] = np.random.randn(100)\n",
    "\n",
    "with h5py.File('resize_dataset.h5', 'r') as hdfid:\n",
    "    dset = hdfid['dataset']\n",
    "    print(dset[99])\n",
    "    print(dset[199])\n",
    "    print(dset[299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
